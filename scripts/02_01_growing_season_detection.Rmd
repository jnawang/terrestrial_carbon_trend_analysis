---
title: "calculate the start and the end of growing season for each site-year"
output: pdf_document
date: "2025-02-25"
author: "Junna Wang"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r raw data location}
rm(list=ls())
# change this location where the raw data will be saved accordingly
# dir_rawdata <- '/Users/jw2946/Documents/stability_project/SiteData/'
dir_rawdata <- '/Volumes/MaloneLab/Research/Stability_Project/SiteData'
#
library(librarian)
shelf(tidyverse, phenofit, data.table, cowplot, ggpubr)
#
```


```{r try the phenofit}
d = MOD13A1$dt %>% subset(site == "CA-NS6" & date >= "2010-01-01" & date <= "2016-12-31") %>%
    .[, .(date, y = EVI/1e4, DayOfYear, QC = SummaryQA)]
d %<>% mutate(t = getRealDate(date, DayOfYear)) %>%
    cbind(d[, as.list(qc_summary(QC, wmin = 0.2, wmid = 0.5, wmax = 0.8))]) %>%
    .[, .(date, t, y, QC_flag, w)]
print(d)
#
#
lambda         <- 8
nptperyear     <- 23
minExtendMonth <- 0.5
maxExtendMonth <- 1
minPercValid   <- 0
wFUN           <- wTSM   # wBisquare
wmin           <- 0.2    #  minimum weight of bad points
methods_fine <- c("AG", "Zhang", "Beck", "Elmore", "Gu")
#
#
# useful variables: t-date of compositing image; w: weights of data point (related to QC_flag, try this); y: EVI; 
# nptperyear: number of images per year.
# wmin: minimum weight of bad points
# south: whether it is in southern hemisphere?
# ylu: 1% and 99% percentiles. 
INPUT <- check_input(d$t, d$y, d$w,
    QC_flag = d$QC_flag,
    nptperyear = nptperyear,
    maxgap = nptperyear / 4, wmin = 0.2, 
    mask_spike = TRUE, 
    south = FALSE
)
#
# Moving growing season division
brks <- season_mov(INPUT,
    list(FUN = "smooth_wWHIT", wFUN = wFUN,
        maxExtendMonth = 3,
        wmin = wmin, r_min = 0.1
    ))
plot_season(INPUT, brks)
#
# 2.4 Curve fitting
fit <- curvefits(INPUT, brks,
    list(
        methods = methods_fine, # ,"klos",, 'Gu'
        wFUN = wFUN,
        iters = 2,
        wmin = wmin,
        # constrain = FALSE,
        nextend = 2,
        maxExtendMonth = maxExtendMonth, minExtendMonth = minExtendMonth,
        minPercValid = minPercValid
    ))
#
l_param <- get_param(fit)
print(l_param$Beck)
# I need to sos and eos of each method: Zhang, Beck, Gu
#
TRS <- c(0.1, 0.2, 0.5)  # Threshold for PhenoTrs
l_pheno <- get_pheno(fit, TRS = TRS, IsPlot = FALSE) # %>% map(~melt_list(., "meth"))
print(l_pheno$doy$Beck)  # I should use Beck, Elmore, and Gu logistics have a more stable performance. 
#
print(l_pheno$doy$Gu)

####how does this package work?
####(1) prepare for INPUT files; (2) smooth the time series; (3) fit the curve; (4) get parameter values. 

```

```{r use GPP to calculate start and end of growing season}
####it turns out I cannot use NEE for this software. 
## This will take 10-20 mins to finish running. 
# a function to merge multiple growing seasons within one year
merge_pheno <- function(df=data.frame()) {
  df$year <- year(df$origin)
  # merge multiple growing seasons within one year
  df_new <- data.frame()
  for (iyear in unique(df$year)) {
    # print(iyear)
    df_sub <- subset(df, year==iyear & !is.na(DER.sos))
    length_gw_piece_DER <- sum(df_sub$DER.eos - df_sub$DER.sos, na.rm=T)
    length_gw_piece_TRS <- sum(df_sub$TRS2.5.eos - df_sub$TRS2.5.sos, na.rm=T)    
    #
    if (nrow(df_sub) > 1) {
      ##check if I need to remove the first and last sub growing season if its duration is longer than 1 week.  
      if (df_sub$DER.eos[1] - df_sub$DER.sos[1] < 7) {
        df_sub <- df_sub[-1, ]
      } 
      if (df_sub$DER.eos[nrow(df_sub)] - df_sub$DER.sos[nrow(df_sub)] < 7) {
        df_sub <- df_sub[-nrow(df_sub),]
      }
      df_sub$DER.eos[1]    <- df_sub$DER.eos[nrow(df_sub)]
      df_sub$TRS1.eos[1]   <- df_sub$TRS1.eos[nrow(df_sub)]          
      df_sub$TRS2.5.eos[1] <- df_sub$TRS2.5.eos[nrow(df_sub)]
      df_sub$TRS5.eos[1]   <- df_sub$TRS5.eos[nrow(df_sub)]
    }
    df_new <- rbind(df_new, data.frame(year=df_sub$year[1], df_sub[1, 3:11], 
                                       length_piece_DER=length_gw_piece_DER, 
                                       length_piece_TRS=length_gw_piece_TRS))
  }
  return(df_new)
}
#
#
####parameter values to run phenofit functions
nptperyear <- 365
wFUN       <- wTSM
wmin = 0.2
methods_fine <- c("AG", "Zhang", "Beck", "Elmore", "Gu")
minExtendMonth <- 0.5
maxExtendMonth <- 1
minPercValid   <- 0
lambda         <- 8
##
####only working on sites that have clear growing seasons
sites_long <- read.csv('../data/long_term_ec_sites.csv')
rm_years   <- read.csv('../data/years_to_remove.csv')
#
files.unzip.Ameri <- list.files(file.path(dir_rawdata, "Ameriflux_FLUXNET", "unzip"), full.names = T)
files.unzip.Europ2020 <- list.files(file.path(dir_rawdata, "FLUXNET2020", "unzip"), full.names = T)
files.unzip.Europ2023 <- list.files(file.path(dir_rawdata, "ICOS_FLUXNET", "unzip_connect2020"), full.names = T)
files.Ameri.ReddyProcGapFill <- list.files(file.path(dir_rawdata, "Ameriflux_BASE", "ReddyProcGapFill"), full.names=T)
#
# sites that grow year-long: MAT >= 20 and in wet climate
sites_grow_yearlong <- c('BR-Sa1', 'US-Esm', 'US-LL1', 'US-LL2', 'US-LL3', 'US-SP3', 'GF-Guy')
#
data_grow_season <- data.frame(site_ID=character(), year=integer(), sos_Beck=double(), eos_Beck=double(), 
                               sos_Elmore=double(), eos_Elmore=double(), sos_Gu=double(), eos_Gu=double(), 
                               sos_TRS=double(), eos_TRS=double(), sos_DER=double(), eos_DER=double(), 
                               length_gs=double(), length_gs_piece=double())
id = 1
#
for (i in 1:nrow(sites_long)) {
#  i = 2
  print(i)
  site_ID <- sites_long$site_ID[i]
  print(site_ID)
  # do not calculate growing season for sites that grows year long. 
  if (site_ID %in% sites_grow_yearlong) {
    next
  }
  #
  if (sites_long$source[i] == "AmeriFlux_FLUXNET") {
    a_DD <- read.csv(files.unzip.Ameri[grepl(pattern=paste0(site_ID, "_FLUXNET_FULLSET_DD"), files.unzip.Ameri)])
  } else if (sites_long$source[i] == "EuropFlux_FLUXNET2023") {
    a_DD <- read.csv(files.unzip.Europ2023[grepl(pattern=paste0(site_ID, "_FLUXNET_DD"), files.unzip.Europ2023)])
  } else if (sites_long$source[i] == "EuropFlux_FLUXNET2020") {
    a_DD <- read.csv(files.unzip.Europ2020[grepl(pattern=paste0(site_ID, "_FLUXNET2015_FULLSET_DD"), files.unzip.Europ2020)])
  } else if (sites_long$source[i] == "AmeriFlux_BASE") {
    a_DD <- read.csv(files.Ameri.ReddyProcGapFill[grepl(pattern=paste0(site_ID, "_EDDYPROC_FULLSET_DD"), files.Ameri.ReddyProcGapFill)])
  }
  a_DD[a_DD==-9999] <- NA
  #
  #
  ####read in daily data
  a_DD$TIMESTAMP <- as.Date(as.character(a_DD$TIMESTAMP), format = "%Y%m%d")
  # remove bad years
  a_DD <- a_DD %>% filter(!year(TIMESTAMP) %in% rm_years$years[rm_years$site_ID==site_ID])
  #
  # using nighttime GPP for the following sites
  # have at least 5-year data and not in the bad daytime partitioned sites and GPP should be positive
  if (sum(!is.na(a_DD$GPP_DT_VUT_REF)) >= 5*365 & !site_ID %in% c("BR-Sa1", "US-NC2", "US-SP3", "US-WCr", "US-Ho1", "US-Ho2", "US-NC4", "US-Kon", "US-MOz", "CH-Lae")) {
    a_DD$GPP <- pmax(a_DD$GPP_DT_VUT_REF, 0.0)
  } else {
    a_DD$GPP <- pmax(a_DD$GPP_NT_VUT_REF, 0.0)
  }
  ggplot(data=a_DD, aes(x=TIMESTAMP, y=GPP)) +
    geom_point()
  #
  a_DD$w <- 1.0     # Data quality of this partition?? this is missing. 
  a_DD$QC_flag <- "good"
  # decide if this is in the southern hemisphere
  south_hemisphere <- ifelse(sites_long$Lat[i]<0, TRUE, FALSE)
  #
  ####prepare for input
  INPUT <- check_input(t=a_DD$TIMESTAMP, y=a_DD$GPP, a_DD$w,
      QC_flag = a_DD$QC_flag,
      nptperyear = nptperyear,
      maxgap = nptperyear / 4, wmin = wmin, 
      mask_spike = TRUE, 
      south = south_hemisphere
  )
  ##
  ####moving growing season division
  brks <- season_mov(INPUT,
      list(FUN = "smooth_wWHIT", wFUN = wFUN,
  #        minpeakdistance = 100,
          maxExtendMonth = 3,
          wmin = wmin, r_min = 0.1, 
          MaxPeaksPerYear = 1,
          MaxTroughsPerYear = 2
      ))
  plot_season(INPUT, brks, title=site_ID)
  #
  ####
  fit <- curvefits(INPUT, brks,
      list(
          methods = methods_fine, # ,"klos",, 'Gu'
          wFUN = wFUN,
          iters = 2,
          wmin = wmin,
          # constrain = FALSE,
          maxExtendMonth = maxExtendMonth, minExtendMonth = minExtendMonth,
          minPercValid = minPercValid
      ))
  #
  TRS <- c(0.1, 0.25, 0.5)  # Threshold for PhenoTrs
  l_pheno <- get_pheno(fit, TRS = TRS, IsPlot = FALSE) # %>% map(~melt_list(., "meth"))
  print(l_pheno$doy$Beck)  # I should use Beck, Elmore, and Gu logistics have a more stable 
  #
  # use the average of the three methods; and then the average of TSR_0.25, DER.sos and DER.eos
  ggplot(data=l_pheno$doy$Gu, aes(x=origin)) +
    geom_point(aes(y=DER.sos, col="blue")) +
    geom_point(aes(y=DER.eos, col="red")) +
    labs(title=paste0(site_ID, "_Gu"))
  #
  ggplot(data=l_pheno$doy$Beck, aes(x=origin)) +
    geom_point(aes(y=DER.sos, col="blue")) +
    geom_point(aes(y=DER.eos, col="red")) +
    labs(title=paste0(site_ID, "_Beck"))
  #
  ggplot(data=l_pheno$doy$Elmore, aes(x=origin)) +
    geom_point(aes(y=DER.sos, col="blue")) +
    geom_point(aes(y=DER.eos, col="red")) +
    labs(title=paste0(site_ID, "_Elmore"))
  #
  # put results into data frame 
  # Merge two sub growing seasons if their distance is shorter than 2 months
  doy_Beck <- merge_pheno(l_pheno$doy$Beck)
  doy_Elmore <- merge_pheno(l_pheno$doy$Elmore)
  doy_Gu <- merge_pheno(l_pheno$doy$Gu)
  #
  nyears <- nrow(doy_Beck)
  data_grow_season[id:(id+nyears-1), 1] <- site_ID
  data_grow_season[id:(id+nyears-1), 2] <- doy_Beck$year
  data_grow_season[id:(id+nyears-1), 3] <- doy_Beck$DER.sos
  data_grow_season[id:(id+nyears-1), 4] <- doy_Beck$DER.eos
  #
  data_grow_season[id:(id+nyears-1), 5] <- doy_Elmore$DER.sos
  data_grow_season[id:(id+nyears-1), 6] <- doy_Elmore$DER.eos  
  #
  data_grow_season[id:(id+nyears-1), 7] <- doy_Gu$DER.sos
  data_grow_season[id:(id+nyears-1), 8] <- doy_Gu$DER.eos    
  #
  data_grow_season[id:(id+nyears-1), 9]  <- rowMeans(cbind(doy_Beck$TRS2.5.sos, doy_Elmore$TRS2.5.sos, doy_Gu$TRS2.5.sos), na.rm=T) 
  data_grow_season[id:(id+nyears-1), 10] <- rowMeans(cbind(doy_Beck$TRS2.5.eos, doy_Elmore$TRS2.5.eos, doy_Gu$TRS2.5.eos), na.rm=T)
  #
  data_grow_season[id:(id+nyears-1), 11] <- rowMeans(cbind(doy_Beck$DER.sos, doy_Elmore$DER.sos, doy_Gu$DER.sos), na.rm=T)
  data_grow_season[id:(id+nyears-1), 12] <- rowMeans(cbind(doy_Beck$DER.eos, doy_Elmore$DER.eos, doy_Gu$DER.eos), na.rm=T)
  #
  data_grow_season[id:(id+nyears-1), 13] <- (data_grow_season[id:(id+nyears-1), 12] - data_grow_season[id:(id+nyears-1), 11]) / 2 + 
                                            (data_grow_season[id:(id+nyears-1), 10] - data_grow_season[id:(id+nyears-1), 9]) / 2
  #
  data_grow_season[id:(id+nyears-1), 14] <- (doy_Beck$length_piece_DER + doy_Beck$length_piece_TRS +
                                             doy_Elmore$length_piece_DER + doy_Elmore$length_piece_TRS +
                                             doy_Gu$length_piece_DER + doy_Gu$length_piece_TRS) / 6
  #
  ggplot(data=data_grow_season[id:(id+nyears-1), ], aes(x=year)) +
    geom_point(aes(y=sos_DER, col="blue")) +
    geom_point(aes(y=eos_DER, col="red")) +
    labs(title=paste0(site_ID, "_average"))
  #
  id <- id + nyears
}
#
data_grow_season <- data_grow_season[!is.na(data_grow_season$year), ]
write.csv(data_grow_season, '../data/growing_season_yearly.csv', row.names = F)
# save the data frame
# look into these sites
# US_NC2: 2021 need to remove. Did I detected this bad quality data before?
# dryland flux should be modeled in different ways. to understand their drivers in more detail. 
# dryland in general can have second growing season. 
# FR_Fbn (72), IT_Cp2(75), ES_Agu(97), ES_Lju(98); should be dealt specifically. 
# CL-SDF(44): this is a large area; 
# US_Ho1: should we use nighttime partition data? Yeah, but still a few years were not well partitioned. 
# US-ICs: 2007 and 2013, we have very small GPP peaks.  
# TODO: 2007 should not be in the datasets. CL-SDF does not work very well. 

```

```{r look at the trends of growing season}
####
data_grow_season <- read.csv('../data/growing_season_yearly.csv')
#
gw_trend <- data.frame()
for (i in 1:length(unique(data_grow_season$site_ID))) {
  site_ID0 <- unique(data_grow_season$site_ID)[i]
  df <- subset(data_grow_season, site_ID==site_ID0)
  ####
  sos_TRS <- summary(lm(data=df, scale(sos_TRS) ~ year))$coefficients[2, c(1)]    #, 4
  eos_TRS <- summary(lm(data=df, scale(eos_TRS) ~ year))$coefficients[2, c(1)]
  sos_DER <- summary(lm(data=df, scale(sos_DER) ~ year))$coefficients[2, c(1)]
  eos_DER <- summary(lm(data=df, scale(eos_DER) ~ year))$coefficients[2, c(1)]
  length_gs <- summary(lm(data=df, scale(length_gs) ~ year))$coefficients[2, c(1)]
  length_gs_piece <- summary(lm(data=df, scale(length_gs_piece) ~ year))$coefficients[2, c(1)]
  ####
  gw_trend <- rbind(gw_trend, data.frame(site_ID=site_ID0, sos_TRS=sos_TRS, eos_TRS=eos_TRS, sos_DER=sos_DER, eos_DER=eos_DER, length_gs=length_gs, length_gs_piece=length_gs_piece) )
  ####
}

gw_trend %>% left_join(sites_long, by="site_ID") %>% filter(category=='cold') %>%
  pivot_longer(cols=2:7, names_to = "gs_metric", values_to = "trend") %>%
  ggplot(aes(x=gs_metric, y=trend)) +
  geom_boxplot() +
  labs(title='Cold climate')

#
gw_trend %>% left_join(sites_long, by="site_ID") %>% filter(category=='dry') %>%
  pivot_longer(cols=2:7, names_to = "gs_metric", values_to = "trend") %>%
  ggplot(aes(x=gs_metric, y=trend)) +
  geom_boxplot() +
  labs(title='Dry climate')

#
gw_trend %>% left_join(sites_long, by="site_ID") %>% filter(category=='wet') %>%
  pivot_longer(cols=2:7, names_to = "gs_metric", values_to = "trend") %>%
  ggplot(aes(x=gs_metric, y=trend)) +
  geom_boxplot() +
  labs(title='wet climate')


gw_trend %>% left_join(sites_long, by="site_ID") %>% filter(category=='cold') %>%
  ggplot(aes(x=abs(Lat), y=sos_TRS)) +      # growing season ends later!
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(method = "pearson")

## How are they different between ENF and DBF ?
sites_20 <- data_grow_season %>% group_by(site_ID) %>% summarise(data_duration=max(year, na.rm=T)-min(year, na.rm=T)+1) %>% filter(data_duration > 19)

## What if we only look at sites longer than 15 years
gw_trend %>% filter(site_ID %in% sites_20$site_ID) %>% left_join(sites_long, by="site_ID") %>% filter(category=='cold') %>%
  pivot_longer(cols=2:7, names_to = "gs_metric", values_to = "trend") %>%
  ggplot(aes(x=gs_metric, y=trend)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter() +
  labs(title='Growing season trends of > 20-year sites')

# Drylands are unique; category!='dry'  

```
